\chapter{Introduction}
\section{Motivation}
In the 1930s Walter Shewart recognized the need for monitoring manufacturing processes in real-time in a robust, systematic way. Thus the development and use of statistical control charts was developed for quickly out of control processes. This allowed for the real-time detection of changes in variation that indicated a degradation in quality in the production process. Shewart's method was one of the first formal frameworks to solve the problem of detecting changes in a distribution of observations that arrive one at a time. This problem would come to be known more generally as the \textit{change point detection problem} and would come to apply across various industries. The following are a few motivating examples.

\subsection{Health Care}
Health care is important area for quickly detecting signal changes in heart rate monitoring \cite{yang2006adaptive} \cite{staudacher2005new}, epilepsy signal segmentation \cite{malladi2013online}, and multi-modal MRI lesion detection \cite{bosc2003automatic} to name a few. It is easy to see why in the context of taking decisions for medical treatment, quickly detecting changes to a patient's health is absolutely necessary for any system to be of practical use, while also balancing the accuracy of these detections. Detecting a false positive or missing a detection could have life-threatening consequences and thus any real-time method must be robust to these types of errors.

%\subsection{Computer Network Surveillance}
%Networks/monitoring systems for intrusions and/or changes in climate or natural disasters.

\subsection{Financial Applications}
The application of accurate and timely change point detection is also very appealing to the finance sector where shifts in asset prices can happen suddenly. Change points in the financial literature are sometimes referred to structural breaks, but for this thesis will use the broader term change points. %\hl{Pepelyshev and Polunchenko \cite{pepelyshev2015real}}

\hl{Look into references from tarokvsky 2015 book:  the articles [52, 358] and references therein.
We also argue that quickest change point detection schemes can be effectively applied to the
analysis of financial data. In particular, quickest change point detection problems are naturally associated with rapid detection of the appearance of an arbitrage in a market [421].}

\section{Characteristics of the change point problem}
A number of surveys of the literature already exist (Aminikhanghahi and Cook \cite{aminikhanghahi2017survey}), therefore we will not cover all existing methods but rather touch upon several, important factors to consider when tackling the change point detection problem. Across the body of literature, these factors determine what methods are available to practitioners. %Furthermore, Bayesian methods that relate to change point detection but will not be covered in this thesis.

The first is the nature of the data that is being observed. If data is generated by a known distribution, such as a univariate Gaussian, then leveraging this information can be very powerful. These models are called \textit{parametric} and come with a greater set of assumptions when applying change point methods. Shewart control charts, CUSUM and autoregressive models are all parametric methods based on \hl{Gaussian-family of distributions}. For an extensive review, see the monograph by Chen and Gupta \cite{chen2011parametric}. On the other hand, if the data is being generated by processes that have no fundamental or well-understood process then modelling particular probability distributions becomes intractable or risky. Therefore, models that do not model particular probability distributions must be used. Methods that fall into this category are known as \textit{non-parametric} models and are more flexible for data that do not easily fall into a well known structure. For reference, see monograph by Brodsky and Darkhovsky \cite{brodsky2013nonparametric}. % Usually this added flexibility is a trade-off with performance and/or speed with parametric models.

The second consideration is to determine what in what scenario the data is analysed. Some algorithms are off-line or batch algorithms in that they are applied in an ex-post fashion after the dataset has been completely acquired. For a recent review of off-line methods see Truong et al.\cite{truong2018review}. The aforementioned Shewart control chart and CUSUM algorithm were both designed for data that is streamed in a near, real-time fashion. In the literature, on-line methods of change point detection are also sometimes called sequential change point detection. For this thesis, we will use the terms interchangeably. For an exhaustive review of sequential change point analysis, see the book by Tartakovsky, Nikiforov, and Basseville  \cite{tartakovsky2014sequential}. %It is possible to convert an on-line algorithm to an off-line algorithm by simply 

The third consideration that is a consequence of detecting change points in an on-line setting is the presence of outliers. This a particularly important concern for on-line methods that are looking for changes in the underlying distribution of points, not a single anomalous data point

\hl{The fourth consideration is determining if there are multiple change points or to assume there is only a single change point to detect. This is a more relevant consideration for off-line change point detection, but could also be relevant for the on-line case if a situation arises where the window of time series under consideration may contain more than one change point.}

Finally, the last point to address is determining exactly what kinds of statistical changes is an algorithm aiming to detect. Many methods focus solely on detecting changes in the mean of a distribution. Other methods focus solely on detecting changes in the variance of a distribution. Finally, some methods are more general and can detect moment changes past the variance and do not focus on any particular one. Methods like kernel change point detection typically operate in this category. 

This thesis will concern itself with on-line change point detection, where data is received in a streaming nature. We assume no prior distribution on the data and operate in a completely non-parametric setting. 
\section{Related Work}

In 2005, Desobry et al. \cite{desobry2005online} developed an on-line kernel change point detection model.

%In 2007, Harchoui and Cappe approached the off-line change point problem with a fixed number of change points by using kernel change point detection. This was further extended to an unknown number of change points in 2012 by Arlot et al. \cite{arlot2012kernel} 



\hl{Finally, Garreau and Arlot extended kernel change points  in the off-line setting of detecting change points. Fundamentally, their method is the kernel version of the following least squares optimization problem:}


\hl{The benefits of this kernel change point detection is that it operates on any kind of data for which a kernel that properly reproduces a Hilbert space can be applied.  %His method is theoretically sound and tested but has not been implemented on very many real datasets nor compared with other benchmark methods.
In an application setting, the user would use some training set to calibrate the kernel and the penalty parameters, to then be tested with appropriate accuracy measures on some out of sample data set.}


Other related work include a 2015 study by Li et al. \cite{li2015m} that propose the use of M-statistics based on the kernel maximum mean discrepancy (MMD) B-test statistic for two-sample testing.

 %The B-test statistic is a recently developed alternative to the MMD that is more efficient; it involves taking an average of the MMD over a partitioning of the data into N blocks.

%In 2016, James et al. \cite{james2016leveraging} proposed using energy statistics to test the significance of a change point that is robust to anomalies. They point out that their work is the first to accurately detect change points with fast time to detection while not being affected by extreme outliers that are not change points. They compare their E-divisive with medians algorithm to the parametric PELT technique. 

\section{Problem Formulation}



\subsection{Performance Measures}
Add information about what performance measures will be used to determine the utility of algorithm. E.g. time to detection, F1 measure, etc.

 

\section{Our Contributions}
Lay out the contributions of this work.