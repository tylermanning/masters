\chapter{Introduction}
\section{Motivation}
Almost 100 years ago, Walter Shewart recognized the need for monitoring manufacturing processes in real-time in a systematic way. Thus the development and use of statistical control charts was developed for quickly out of control processes \cite{shewhart1931economic}. This allowed for the real-time detection of changes in variation that indicated a degradation in quality in the production process. Shewart's method was one of the first formal frameworks to solve the problem of detecting changes in a distribution of observations that arrive one at a time. This problem would come to be known more generally as the \textit{change point detection problem} and would come to apply across various industries. The following are a few motivating examples.

\subsection{Health Care}
Health care is important area for quickly detecting signal changes in heart rate monitoring \cite{yang2006adaptive} \cite{staudacher2005new}, epilepsy signal segmentation \cite{malladi2013online}, and multi-modal MRI lesion detection \cite{bosc2003automatic} to name a few. It is easy to see why in the context of taking decisions for medical treatment, quickly detecting changes to a patient's health is absolutely necessary for any system to be of practical use, while also balancing the accuracy of these detections. Detecting a false positive or missing a detection could have life-threatening consequences and thus any real-time method must be robust to these types of errors.

%\subsection{Computer Network Surveillance}
%Networks/monitoring systems for intrusions and/or changes in climate or natural disasters.

\subsection{Financial Applications}
The application of accurate and timely change point detection is also very appealing to the finance sector where shifts in asset prices can happen suddenly. Change points in the financial literature are sometimes referred to structural breaks, but for this thesis will use the broader term change points. %\hl{Pepelyshev and Polunchenko \cite{pepelyshev2015real}}

\hl{Look into references from tarokvsky 2015 book:  the articles [52, 358] and references therein.
We also argue that quickest change point detection schemes can be effectively applied to the
analysis of financial data. In particular, quickest change point detection problems are naturally associated with rapid detection of the appearance of an arbitrage in a market [421].}

\section{Characteristics of the change point problem}
A number of surveys of the literature already exist \cite{aminikhanghahi2017survey}, therefore we will not cover all existing methods but rather touch upon several, important factors to consider when tackling the change point detection problem. Across the body of literature, these factors determine what methods are available to practitioners. %Furthermore, Bayesian methods that relate to change point detection but will not be covered in this thesis.

The first factor is selecting between \textit{parametric} and \textit{non-parametric} techniques. Deciding between these two broad techniques is dependent on the prior knowledge one wants to encode into the problem. For example, if it is known that data is generated by a distribution from the exponential family of distributions, then we can subset the problem from the space of all possible distributions to a smaller space of distributions. Shewart control charts, CUSUM and autoregressive change-point techniques are all parametric techniques based on \hl{Gaussian-family of distributions, also add reference fo AR } \cite{page1954continuous}. For an extensive review, see the monograph by Chen and Gupta \cite{chen2011parametric}. In certain settings, it is not possible to leverage information about the data. Therefore, non-parametric techniques that do not assume particular distributional parameters must be used \cite{brodsky2013nonparametric}.%These  techniques are often more flexible for data....  

% . On the other hand, if the data is being generated by processes that have no fundamental or well-understood process then modelling particular probability distributions becomes intractable or risky. Therefore, models that do not model particular probability distributions must be used. For reference, see monograph by Brodsky and Darkhovsky \cite{brodsky2013nonparametric}. % Usually this added flexibility is a trade-off with performance and/or speed with parametric models.

The second factor is to deciding whether change-point detection should be applied \textit{offline} or \textit{online}. Some algorithms are off-line or batch algorithms in that they are applied in an ex-post fashion after the dataset has been completely acquired \cite{truong2018review}. The aforementioned Shewart control chart and CUSUM algorithm were both designed for data that is streamed in a real-time fashion. In the literature, on-line methods of change point detection are also referred to sequential change point detection  \cite{tartakovsky2014sequential}. For this thesis, we will use the terms interchangeably.% For an exhaustive review of sequential change point analysis, see the book by Tartakovsky, Nikiforov, and Basseville  \cite{tartakovsky2014sequential}. %It is possible to convert an on-line algorithm to an off-line algorithm by simply 

%The third consideration that is a consequence of detecting change points in an on-line setting is the presence of outliers. This a particularly important concern for on-line methods that are looking for changes in the underlying distribution of points, not a single anomalous data point

\hl{The third factor is determining if there are multiple change points or to assume there is only a single change point to detect. This is a more relevant consideration for off-line change point detection, but could also be relevant for the on-line case if a situation arises where the window of time series under consideration may contain more than one change point.}

Finally, the last point to address is determining exactly what kinds of statistical changes is an algorithm aiming to detect. Many methods focus solely on detecting changes in the mean of a distribution. Other methods focus solely on detecting changes in the variance of a distribution. Finally, some methods are more general and can detect moment changes past the variance and do not focus on any particular one. Methods like kernel change point detection typically operate in this category. 

This thesis will concern itself with on-line change point detection, where data is received in a streaming nature. We assume no prior distributional characteristics on the data and operate in a completely non-parametric setting. 
\section{Related Work}

In 2005, Desobry et al. \cite{desobry2005online} developed an on-line kernel change point detection model based on single class support vector machines ($\nu$-SVMs). The authors train a single class support vector on a past set, $\mathbf{x}_{t,1}={x_{t-m_1},...,x_{t-1}}$ of size $m_1$ and train another single class support vector on a future set $\mathbf{x}_{t,2}={x_t,...,x_{t+m_2-1}}$ of size $m2$. A ratio is then computed between the two sets that acts as the dissimilarity measure in Hilbert space. If the points are sufficiently dissimilar over some predetermined threshold,$\eta$, then a change point is assigned to the time spitting the two sets of data.% Desobry argues that a dissimilarity measure between kernel projection of points in a Hilbert space should estimate the \textit{density supports} rather than estimate the probability distributions of each set of points. 

In 2007, Harchoui and Cappe \cite{harchaoui2007retrospective} approached the off-line change point problem with a fixed number of change points by using kernel change point detection. This was further extended to an unknown number of change points in 2012 by Arlot et al. \cite{arlot2012kernel}. Finally, Garreau and Arlot extended this in line of research kernel change points in the off-line setting of detecting change points. Fundamentally, their method is the kernel version of the following least squares optimization problem:


\hl{The benefits of this kernel change point detection is that it operates on any kind of data for which a kernel that properly reproduces a Hilbert space can be applied.  %His method is theoretically sound and tested but has not been implemented on very many real datasets nor compared with other benchmark methods.
In an application setting, the user would use some training set to calibrate the kernel and the penalty parameters, to then be tested with appropriate accuracy measures on some out of sample data set.}


Other related work include a 2015 study by Li et al. \cite{li2015m} that propose the use of M-statistics based on the kernel maximum mean discrepancy (MMD) B-test statistic for two-sample testing.
%https://media.nips.cc/nipsbooks/nipspapers/paper_files/nips28/reviews/1852.html

 %The B-test statistic is a recently developed alternative to the MMD that is more efficient; it involves taking an average of the MMD over a partitioning of the data into N blocks.

%In 2016, James et al. \cite{james2016leveraging} proposed using energy statistics to test the significance of a change point that is robust to anomalies. They point out that their work is the first to accurately detect change points with fast time to detection while not being affected by extreme outliers that are not change points. They compare their E-divisive with medians algorithm to the parametric PELT technique. 

\section{Problem Formulation}



\subsection{Performance Measures}
Add information about what performance measures will be used to determine the utility of algorithm. E.g. time to detection, F1 measure, etc.

 

\section{Our Contributions}
Lay out the contributions of this work.