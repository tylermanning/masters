\chapter{Introduction}
\section{Motivation}
Recent advances in neural network architecture and utilization of large amounts of data have led to astonishing results in fields such as image recognition, natural language processing, and speech recognition [add citations]. Many modern techniques such as long short term memory neural networks and convolution neural networks have been applied to time series forecasting and, while the results are promising, it remains to be seen whether such techniques can significantly outperform classical statistical methods \cite{makridakis2018statistical}. This opens the door for novel ideas to be tried and benchmarked against existing, classical methods.

In this thesis, we concern ourselves with abrupt regime changes in time series that indicate the beginning or end of significant trends of a time series. There are two main tasks in tackling this problem. The first is identifying when a time series has a collective outlier that is accurately discernible from noise and not simply a contextual outlier. The second is we would like regime changes to be detected as soon as possible. 

Over the past decade, time series classification has seen extremely competitive results using simple nearest neighbour techniques \cite{bagnall2017great}. Fundamentally it involves a distance calculation between two sequences, followed by a one nearest neighbour classifier. The most common distance functions used for this is the Euclidean distance or some variant thereof. 

\section{Previous Work}
[make this more related to the exact problem you are solving not a literature review]

Detecting abrupt changes in a time series is a common task in time series analysis and signal processing. Many outlier detection methods exist such as . A closely related topic is change point detection which focuses on discerning  when possible regime shifts occur in a time series. Here the regime shifts indicate collective outliers and are considered out of place when compared to another regime in the time series.

Broadly speaking there are two main categories that methods fall into, parametric and non-parametric modelling. Parametric models attempt to model the data directly through parametrization of the phenomenon being measured. This makes sense for data that are based on well-understood theoretical models or natural phenomenon. When no theoretical models exist and data is generated in then a non-parametric model is suitable.

Another point brought up by dog \cite{aminikhanghahi2017survey} is the fact that

\section{Data Sources}

Inspired by twitter trend detection research, the ultimate goal is to test our contribution on labelled twitter count data that have some mix of trending and non-trending sequences. Since this data would be costly to acquire and label. This will not be used to test the performance of this work. Instead, the following sources of data will be used:
 \subsection{Synthetic datasets}
 \subsection{Public datasets}
\subsection{Private dataset}
  
\section{Latent Source Model}
The set of examples
$\mathcal{Y}$ is the set of possible labels ${0,1}$ to denote trend or no trend. Therefore, the learner will attempt to learn a model using the training set that is defined as $\mathcal{X} \times \mathcal{Y} : \mathcal{S} = ((x_1,y_1), (x_2,y_2)...(x_m,y_m))$. The term training set is used loosely here as no model parameters are actually learned.

Chen et al.  \cite{NIPS2013_5116} describe a \textit{latent source} model for detecting sudden trends on twitter. The model is a data-driven, non-para metric classifier that is capable of classifying an observed, streaming time series as either a trending time series or not a trending time series. They construct the time series using the counts of a twitter string (or hash-tag) over time, binned at specific intervals. The approach taken is based on the assumption that there are fundamental behaviours that generate tweets when they trend compared to when they do not trend. These unknown fundamental behaviours are called \textit{latent sources}.  

In this supervised learning setting, data is labelled with either ``trend" or ``no trend". Each labelled data point is referred to as a reference signal or latent source and is denoted as $r$. The entire a set of reference signals is denoted as $R$. Therefore, we have a binary classifier where a new data point is classified into sets $R+$ or $R-$, reflecting the set of trending signals and non-trending signals respectively. 

Nikolov  \cite{nikolov2012trend} specifies an observation, $s$, is generated by a latent source
$r$ if $s$ is a noisy version of $r$ and proposes the following stochastic model:

\begin{equation}
\mathbb{P}(s \text{ generated by }  r) \propto e^{-\lambda d(r,s)} 
\end{equation}
The distance function used is the sum of squares Euclidean distance:
\begin{equation}
d(r,s) = \sum_{i=1}^N (r_i - s_i)^2 
\end{equation}
Here the observed signal $s$ and the reference signal $r$ are of length $N$. Note that the squared Euclidean distance is not a metric as it does satisfy the triangle inequality. However, as the authors point out,  the function $d$ may be replaced by any function that is symmetric, positive definite, and convex. 
Once the distance is computed, the weight of its vote is determined by: 
\begin{equation}
W(r,s) = e^{-\lambda d(r,s)}
\end{equation}
Where the scaling parameter $\lambda$ can be thought of as a ``sphere of influence" that allows the user to tune the relative importance of a similar or dissimilar time series. For example, a large value of $\lambda$ generates very small weights for elements of $R$ that are very different from $s$.

Finally, the weights are summed across all the items in the trending set, $R+$, and divided by all time series in the non-trending set, $R-$, to create a final metric $\eta$:
\begin{equation}
\eta(s)=\frac{\mathbb{P}(+|s)}{\mathbb{P}{(-|s)}} =\frac{\sum_{r \in R+} W(r,s)}{\sum_{r \in R-}W(r,s)}
\end{equation}
The estimated classification of an observed time series, $s$, can then be defined as:
\begin{equation}
  \hat{L}(s)=\begin{cases}
    +, & \text{if $\eta(s)>\theta$}.\\
    -, & \text{if $\eta(s) \leq \theta$}.
  \end{cases}
\end{equation}
Where $\theta$ defines the threshold for classification and is typically is set to $1$. However, it can be tuned depending on the use case. For example, in cases where false positives are costly, the value of $\theta$ can be set to greater than $1$. 

%Chen et al. \cite{} expanded on this estimator by also proposing a classification based on the $k$ nearest neighbors of $s$ among all training time series where all other votes are set to 0. By setting $k=1$  (1-NN), we have an alternative nearest neighbour estimator:

\section{Our Contributions}
Lay out the contributions of this work.